from sklearn.metrics import classification_report, accuracy_score
import os

os.environ["CUDA_VISIBLE_DEVICES"] = "0"
import torch
from sklearn.metrics.pairwise import cosine_similarity
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import abc
from rkd import RKD
import torch.nn.utils as utils
import torchvision.models as models
from torchvision import transforms
from torch.utils.data import DataLoader
from torch.utils.data import TensorDataset
import torch.nn.init as init
import pickle
import json, os
import argparse
import config_file
import random
from PIL import Image
import sys
from loss_func import SupConLoss

import warnings

warnings.filterwarnings('ignore')

sys.path.append('/../image_part')
alpha = 0.5
lambda_kd = 5.0
temp1 = 0.5
parser = argparse.ArgumentParser()
parser.description = "ini"
parser.add_argument("-t", "--task", type=str, default="weibo2")
parser.add_argument("-g", "--gpu_id", type=str, default="1")
parser.add_argument("-c", "--config_name", type=str, default="single3.json")
parser.add_argument("-T", "--thread_name", type=str, default="Thread-1")
parser.add_argument("-d", "--description", type=str, default="exp_description")
args = parser.parse_args()


def process_config(config):
    for k, v in config.items():
        config[k] = v[0]
    return config


class PGD(object):

    def __init__(self, model, emb_name, epsilon=1., alpha=0.3):
        self.model = model
        self.emb_name = emb_name
        self.epsilon = epsilon
        self.alpha = alpha
        self.emb_backup = {}
        self.grad_backup = {}

    def attack(self, is_first_attack=False):
        for name, param in self.model.named_parameters():
            if param.requires_grad and self.emb_name in name:
                if is_first_attack:
                    self.emb_backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm != 0:
                    r_at = self.alpha * param.grad / norm
                    param.data.add_(r_at)
                    param.data = self.project(name, param.data, self.epsilon)

    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and self.emb_name in name:
                assert name in self.emb_backup
                param.data = self.emb_backup[name]
        self.emb_backup = {}

    def project(self, param_name, param_data, epsilon):
        r = param_data - self.emb_backup[param_name]
        if torch.norm(r) > epsilon:
            r = epsilon * r / torch.norm(r)
        return self.emb_backup[param_name] + r

    def backup_grad(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and param.grad is not None:
                self.grad_backup[name] = param.grad.clone()

    def restore_grad(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and param.grad is not None:
                param.grad = self.grad_backup[name]


class TransformerBlock(nn.Module):

    def __init__(self, input_size, d_k=16, d_v=16, n_heads=8, is_layer_norm=False, attn_dropout=0.1):
        super(TransformerBlock, self).__init__()
        self.n_heads = n_heads
        self.d_k = d_k if d_k is not None else input_size
        self.d_v = d_v if d_v is not None else input_size

        self.is_layer_norm = is_layer_norm
        if is_layer_norm:
            self.layer_morm = nn.LayerNorm(normalized_shape=input_size)

        self.W_q = nn.Parameter(torch.Tensor(input_size, n_heads * d_k))
        self.W_k = nn.Parameter(torch.Tensor(input_size, n_heads * d_k))
        self.W_v = nn.Parameter(torch.Tensor(input_size, n_heads * d_v))

        self.W_o = nn.Parameter(torch.Tensor(d_v * n_heads, input_size))
        self.linear1 = nn.Linear(input_size, input_size)
        self.linear2 = nn.Linear(input_size, input_size)

        self.dropout = nn.Dropout(attn_dropout)
        self.__init_weights__()

    def __init_weights__(self):
        init.xavier_normal_(self.W_q)
        init.xavier_normal_(self.W_k)
        init.xavier_normal_(self.W_v)
        init.xavier_normal_(self.W_o)

        init.xavier_normal_(self.linear1.weight)
        init.xavier_normal_(self.linear2.weight)

    def FFN(self, X):
        output = self.linear2(F.relu(self.linear1(X)))
        output = self.dropout(output)
        return output

    def scaled_dot_product_attention(self, Q, K, V, episilon=1e-6):
        '''
        :param Q: (*, max_q_words, n_heads, input_size)
        :param K: (*, max_k_words, n_heads, input_size)
        :param V: (*, max_v_words, n_heads, input_size)
        :param episilon:
        :return:
        '''
        temperature = self.d_k ** 0.5
        Q_K = torch.einsum("bqd,bkd->bqk", Q, K) / (temperature + episilon)
        Q_K_score = F.softmax(Q_K, dim=-1)
        Q_K_score = self.dropout(Q_K_score)

        V_att = Q_K_score.bmm(V)
        return V_att

    def multi_head_attention(self, Q, K, V):
        bsz, q_len, _ = Q.size()
        bsz, k_len, _ = K.size()
        bsz, v_len, _ = V.size()

        Q_ = Q.matmul(self.W_q).view(bsz, q_len, self.n_heads, self.d_k)
        K_ = K.matmul(self.W_k).view(bsz, k_len, self.n_heads, self.d_k)
        V_ = V.matmul(self.W_v).view(bsz, v_len, self.n_heads, self.d_v)

        Q_ = Q_.permute(0, 2, 1, 3).contiguous().view(bsz * self.n_heads, q_len, self.d_k)
        K_ = K_.permute(0, 2, 1, 3).contiguous().view(bsz * self.n_heads, q_len, self.d_k)
        V_ = V_.permute(0, 2, 1, 3).contiguous().view(bsz * self.n_heads, q_len, self.d_v)

        V_att = self.scaled_dot_product_attention(Q_, K_, V_)
        V_att = V_att.view(bsz, self.n_heads, q_len, self.d_v)
        V_att = V_att.permute(0, 2, 1, 3).contiguous().view(bsz, q_len, self.n_heads * self.d_v)

        output = self.dropout(V_att.matmul(self.W_o))
        return output

    def forward(self, Q, K, V):

        V_att = self.multi_head_attention(Q, K, V)

        if self.is_layer_norm:
            X = self.layer_morm(Q + V_att)
            output = self.layer_morm(self.FFN(X) + X)
        else:
            X = Q + V_att
            output = self.FFN(X) + X
        return output


class NeuralNetwork(nn.Module):

    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.best_acc = 0
        self.init_clip_max_norm = None
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    @abc.abstractmethod
    def forward(self, x_tid, x_text, x_UserReview):
        pass

    def mfan(self, Tea_model, x_tid, x_text, x_UserReview, y, loss, criterionKD, i, total, params, pgd_word):

        Tea_model.eval()
        logit = Tea_model.predict(x_tid, x_text, x_UserReview)

        self.optimizer.zero_grad()
        logit_original, embedding_train = self.forward(x_tid, x_text, x_UserReview)
        kd_loss = criterionKD(logit, logit_original) * lambda_kd  # 蒸馏损失

        loss_classification = loss(logit_original, y)

        loss_defense = loss_classification + kd_loss
        loss_defense.backward()

        K = 3
        pgd_word.backup_grad()
        for t in range(K):
            pgd_word.attack(is_first_attack=(t == 0))
            if t != K - 1:
                self.zero_grad()
            else:
                pgd_word.restore_grad()
            loss_adv, embedding_adv = self.forward(x_tid, x_text, x_UserReview)
            logit = Tea_model.predict(x_tid, x_text, x_UserReview)

            kd_loss = criterionKD(logit, loss_adv) * lambda_kd  # 蒸馏损失

            loss_adv = loss(loss_adv, y) + kd_loss

            loss_adv.backward()

        pgd_word.restore()

        self.optimizer.step()
        corrects = (torch.max(logit_original, 1)[1].view(y.size()).data == y.data).sum()
        accuracy = 100 * corrects / len(y)
        print(
            'Batch[{}/{}] - loss: {:.6f}  accuracy: {:.4f}%({}/{})'.format(i + 1, total,
                                                                           loss_defense.item(),
                                                                           accuracy,
                                                                           corrects,
                                                                           y.size(0)))

    def fit(self, Tea_model, X_train_tid, X_train, X_train_UserReview, y_train,
            X_dev_tid, X_dev, X_dev_UserReview, y_dev):

        if torch.cuda.is_available():
            self.cuda()
        batch_size = self.config['batch_size']
        self.optimizer = torch.optim.Adam(self.parameters(), lr=2e-3, weight_decay=0)

        X_train_tid = torch.LongTensor(X_train_tid)
        X_train = torch.LongTensor(X_train)
        X_train_UserReview = torch.LongTensor(X_train_UserReview)
        y_train = torch.LongTensor(y_train)

        dataset = TensorDataset(X_train_tid, X_train, X_train_UserReview, y_train)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

        loss = nn.CrossEntropyLoss()
        criterionKD = RKD(25, 50)

        params = [(name, param) for name, param in self.named_parameters()]
        pgd_word = PGD(self, emb_name='word_embedding', epsilon=6, alpha=1.8)
        for epoch in range(self.config['epochs']):
            print("\nEpoch ", epoch + 1, "/", self.config['epochs'],"正在训练......")
            self.train()
            # avg_loss = 0
            # avg_acc = 0
            for i, data in enumerate(dataloader):
                total = len(dataloader)
                batch_x_tid, batch_x_text, batch_x_UserReview, batch_y = (item.cuda(device=self.device) for item in
                                                                          data)
                self.mfan(Tea_model, batch_x_tid, batch_x_text, batch_x_UserReview, batch_y, loss, criterionKD, i,
                          total, params,
                          pgd_word)

                if self.init_clip_max_norm is not None:
                    utils.clip_grad_norm_(self.parameters(), max_norm=self.init_clip_max_norm)
            self.evaluate(X_dev_tid, X_dev, X_dev_UserReview, y_dev)

    def evaluate(self, X_dev_tid, X_dev, X_dev_UserReview, y_dev):
        y_pred = self.predict(X_dev_tid, X_dev, X_dev_UserReview)
        acc = accuracy_score(y_dev, y_pred)

        if acc > self.best_acc:
            self.best_acc = acc
            torch.save(self.state_dict(), self.config['save_path'])
            print(classification_report(y_dev, y_pred, target_names=self.config['target_names'], digits=5))
            print("Val set acc:", acc)
            print("Best val set acc:", self.best_acc)
            print("save model!!!   at ", self.config['save_path'])

    def predict(self, X_test_tid, X_test, X_test_UserReview):
        if torch.cuda.is_available():
            self.cuda()
        self.eval()
        y_pred = []
        X_test_tid = torch.LongTensor(X_test_tid).cuda()
        X_test = torch.LongTensor(X_test).cuda()
        X_test_UserReview = torch.LongTensor(X_test_UserReview).cuda()

        dataset = TensorDataset(X_test_tid, X_test, X_test_UserReview)
        dataloader = DataLoader(dataset, batch_size=50)

        for i, data in enumerate(dataloader):
            with torch.no_grad():
                batch_x_tid, batch_x_text, batch_x_UserReview = (item.cuda(device=self.device) for item in data)
                logits, embedding_eval = self.forward(batch_x_tid, batch_x_text, batch_x_UserReview)
                predicted = torch.max(logits, dim=1)[1]
                y_pred += predicted.data.cpu().numpy().tolist()
        return y_pred


class NeuralNetwork2(nn.Module):

    def __init__(self):
        super(NeuralNetwork2, self).__init__()
        self.best_acc = 0
        self.init_clip_max_norm = None
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    @abc.abstractmethod
    def forward(self, x_tid, x_text, x_UserReview):
        pass

    # def predict(self, X_test_tid, X_test, X_test_UserReview):
    #     logits, embedding_eval = self.forward(X_test_tid, X_test, X_test_UserReview)
    #     return logits
    def predict(self, X_test_tid, X_test, X_test_UserReview):
        if torch.cuda.is_available():
            self.cuda()
        # self.eval()
        # y_pred = []
        # X_test_tid = torch.LongTensor(X_test_tid).cuda()
        # X_test = torch.LongTensor(X_test).cuda()
        # X_test_UserReview = torch.LongTensor(X_test_UserReview).cuda()

        # dataset = TensorDataset(X_test_tid, X_test, X_test_UserReview)
        # dataloader = DataLoader(dataset, batch_size=50)

        # for i, data in enumerate(dataloader):
        #     with torch.no_grad():
        #         # batch_x_tid, batch_x_text, batch_x_UserReview = (item.cuda(device=self.device) for item in data)
        #         # logits, dist, embedding_eval = self.forward(batch_x_tid, batch_x_text, batch_x_UserReview)
        #         logits, dist, embedding_eval = self.forward(X_test_tid, X_test, X_test_UserReview)
        #         predicted = torch.max(logits, dim=1)[1]
        #         y_pred += predicted.data.cpu().numpy().tolist()
        with torch.no_grad():
            # batch_x_tid, batch_x_text, batch_x_UserReview = (item.cuda(device=self.device) for item in data)
            # logits, dist, embedding_eval = self.forward(batch_x_tid, batch_x_text, batch_x_UserReview)
            logits, embedding_eval = self.forward(X_test_tid, X_test, X_test_UserReview)
            # predicted = torch.max(logits, dim=1)[1]
            # y_pred += predicted.data.cpu().numpy().tolist()
        return logits


class resnet50():
    def __init__(self):
        self.newid2imgnum = config['newid2imgnum']
        self.model = models.resnet50(pretrained=True).cuda()
        self.model.fc = nn.Linear(2048, 300).cuda()
        torch.nn.init.eye_(self.model.fc.weight)
        self.path = os.path.dirname(os.getcwd()) + '/dataset/weibo/weibo_images/weibo_images_all/'
        self.trans = self.img_trans()

    def img_trans(self):
        transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )])
        return transform

    def forward(self, xtid):
        img_path = []
        img_list = []
        for newid in xtid.cpu().numpy():
            imgnum = self.newid2imgnum[newid]
            imgpath = self.path + imgnum + '.jpg'
            im = np.array(self.trans(Image.open(imgpath)))
            im = torch.from_numpy(np.expand_dims(im, axis=0)).to(torch.float32)
            img_list.append(im)
        batch_img = torch.cat(img_list, dim=0).cuda()
        img_output = self.model(batch_img)
        return img_output


class MFAN(NeuralNetwork):
    def __init__(self, config):
        super(MFAN, self).__init__()
        self.config = config
        embedding_weights = config['embedding_weights']
        V, D = embedding_weights.shape
        maxlen = config['maxlen']
        dropout_rate = config['dropout']

        self.mh_attention = TransformerBlock(input_size=300, n_heads=8, attn_dropout=0)
        self.word_embedding = nn.Embedding(num_embeddings=V, embedding_dim=D, padding_idx=0,
                                           _weight=torch.from_numpy(embedding_weights))

        self.image_embedding = resnet50()
        self.convs = nn.ModuleList([nn.Conv1d(300, 100, kernel_size=K) for K in config['kernel_sizes']])
        self.max_poolings = nn.ModuleList([nn.MaxPool1d(kernel_size=maxlen - K + 1) for K in config['kernel_sizes']])

        self.dropout = nn.Dropout(dropout_rate)
        self.relu = nn.ReLU()
        self.fc3 = nn.Linear(300, 300)
        self.fc4 = nn.Linear(900, 600)
        self.fc1 = nn.Linear(300, 300)
        self.fc2 = nn.Linear(in_features=300, out_features=config['num_classes'])
        self.init_weight()

    def init_weight(self):
        init.xavier_normal_(self.fc1.weight)
        init.xavier_normal_(self.fc2.weight)
        init.xavier_normal_(self.fc3.weight)
        init.xavier_normal_(self.fc4.weight)

    def forward(self, X_tid, X_text, X_UserReview):
        X_text = self.word_embedding(X_text)  # 经过word_embedding后维度为：(64,50,300)
        if self.config['user_self_attention'] == True:
            X_text = self.mh_attention(X_text, X_text, X_text)  # (64,50,300)
        X_text = X_text.permute(0, 2, 1)  # (64,300,50) 维度变换

        # 文本 CNN
        conv_block = []
        for _, (Conv, max_pooling) in enumerate(zip(self.convs, self.max_poolings)):
            act = self.relu(Conv(X_text))
            pool = max_pooling(act)
            pool = torch.squeeze(pool)
            conv_block.append(pool)
        conv_feature = torch.cat(conv_block, dim=1)  # (64,600)
        text_feature = conv_feature

        bsz = text_feature.size()[0]
        self_att_t = self.mh_attention(text_feature.view(bsz, -1, 300), text_feature.view(bsz, -1, 300), \
                                       text_feature.view(bsz, -1, 300)).view(bsz, 300)

        a1 = self.relu(self.dropout(self.fc3(self_att_t)))
        a1 = self.relu(self.fc1(a1))
        d1 = self.dropout(a1)
        output = self.fc2(d1)

        return output, d1



class MFAN2(NeuralNetwork2):
    def __init__(self, config):
        super(MFAN2, self).__init__()
        self.config = config  # 保存有：1.节点的向量表示  2.字符的向量表示  3.帖子编号-图片编号
        embedding_weights = config['embedding_weights']
        V, D = embedding_weights.shape  # 17207，300
        maxlen = config['maxlen']  # 50
        dropout_rate = config['dropout']

        self.mh_attention = TransformerBlock(input_size=300, n_heads=8, attn_dropout=0)
        self.word_embedding = nn.Embedding(num_embeddings=V, embedding_dim=D, padding_idx=0,
                                           _weight=torch.from_numpy(embedding_weights))
        self.cosmatrix = self.calculate_cos_matrix()  # 节点的余弦相似度(6963,6963)

        self.image_embedding = resnet50()
        self.convs = nn.ModuleList([nn.Conv1d(300, 100, kernel_size=K) for K in config['kernel_sizes']])
        self.max_poolings = nn.ModuleList([nn.MaxPool1d(kernel_size=maxlen - K + 1) for K in config['kernel_sizes']])

        self.dropout = nn.Dropout(dropout_rate)
        self.relu = nn.ReLU()
        # self.fc3 = nn.Linear(1800, 900)
        self.fc3 = nn.Linear(900, 600)
        self.fc4 = nn.Linear(900, 600)
        self.fc1 = nn.Linear(600, 300)
        self.fc2 = nn.Linear(in_features=300, out_features=config['num_classes'])
        self.alignfc_g = nn.Linear(in_features=300, out_features=300)
        self.alignfc_t = nn.Linear(in_features=300, out_features=300)
        self.init_weight()

    def calculate_cos_matrix(self):
        a, b = torch.from_numpy(config['node_embedding']), torch.from_numpy(config['node_embedding'].T)
        c = torch.mm(a, b)
        aa = torch.mul(a, a)
        bb = torch.mul(b, b)
        asum = torch.sqrt(torch.sum(aa, dim=1, keepdim=True))
        bsum = torch.sqrt(torch.sum(bb, dim=0, keepdim=True))
        norm = torch.mm(asum, bsum)
        res = torch.div(c, norm)
        return res

    def init_weight(self):
        init.xavier_normal_(self.fc1.weight)
        init.xavier_normal_(self.fc2.weight)
        init.xavier_normal_(self.fc3.weight)
        init.xavier_normal_(self.fc4.weight)

    def forward(self, X_tid, X_text, X_UserReview):
        # X_tid：post节点编号,64条帖子编号为一个批次。保存64个帖子编号。----(64)
        # X_text：对应post的内容text,切分后的50个字符,对应是每一个字符的编号。----(64, 50)
        X_text = self.word_embedding(X_text)  # 经过word_embedding后维度为：(64,50,300)
        if self.config['user_self_attention'] == True:
            X_text = self.mh_attention(X_text, X_text, X_text)  # (64,50,300)
        X_text = X_text.permute(0, 2, 1)  # (64,300,50) 维度变换

        # 用户评论
        X_UserReview = self.word_embedding(X_UserReview)
        X_UserReview = X_UserReview.permute(0, 2, 1)
        conv_block1 = []
        # 文本 CNN
        for _, (Conv, max_pooling) in enumerate(zip(self.convs, self.max_poolings)):
            act1 = self.relu(Conv(X_UserReview))
            pool1 = max_pooling(act1)
            pool1 = torch.squeeze(pool1)
            conv_block1.append(pool1)

        conv_feature1 = torch.cat(conv_block1, dim=1)  # (64,600)
        UserReview_feature = conv_feature1  # (64,300)

        # 图像 RestNet50
        iembedding = self.image_embedding.forward(X_tid)  # (64,300)
        conv_block = []
        # 文本 CNN
        for _, (Conv, max_pooling) in enumerate(zip(self.convs, self.max_poolings)):
            act = self.relu(Conv(X_text))
            pool = max_pooling(act)
            pool = torch.squeeze(pool)
            conv_block.append(pool)

        conv_feature = torch.cat(conv_block, dim=1)  # (64,600)
        text_feature = conv_feature

        bsz = text_feature.size()[0]

        self_att_t = self.mh_attention(text_feature.view(bsz, -1, 300), text_feature.view(bsz, -1, 300), \
                                       text_feature.view(bsz, -1, 300))
        self_att_i = self.mh_attention(iembedding.view(bsz, -1, 300), iembedding.view(bsz, -1, 300), \
                                       iembedding.view(bsz, -1, 300))
        text_enhanced = self.mh_attention(self_att_i.view((bsz, -1, 300)), self_att_t.view((bsz, -1, 300)), \
                                          self_att_t.view((bsz, -1, 300))).view(bsz, 300)
        align_text = self.alignfc_t(text_enhanced)
        # dist = [align_text]

        self_att_t = text_enhanced.view((bsz, -1, 300))
        co_att_ti = self.mh_attention(self_att_t, self_att_i, self_att_i).view(bsz, 300)
        co_att_it = self.mh_attention(self_att_i, self_att_t, self_att_t).view(bsz, 300)

        att_feature = torch.cat((co_att_ti, co_att_it, UserReview_feature), dim=1)
        a1 = self.relu(self.dropout(self.fc3(att_feature)))
        a1 = self.relu(self.fc1(a1))
        d1 = self.dropout(a1)
        output = self.fc2(d1)

        # return output, dist, d1
        return output, d1


def load_dataset():
    pre = os.path.dirname(os.getcwd()) + '/dataset/weibo/weibo_files'
    X_train_tid, X_train, X_train_UserReview, y_train, word_embeddings, _ = pickle.load(
        open(pre + "/train.pkl", 'rb'))
    X_dev_tid, X_dev, X_dev_UserReview, y_dev = pickle.load(open(pre + "/dev.pkl", 'rb'))
    X_test_tid, X_test, X_test_UserReview, y_test = pickle.load(open(pre + "/test.pkl", 'rb'))
    config['embedding_weights'] = word_embeddings
    config['node_embedding'] = pickle.load(open(pre + "/node_embedding.pkl", 'rb'))[0]

    with open(pre + '/new_id_dic.json', 'r') as f:
        newid2mid = json.load(f)
        newid2mid = dict(zip(newid2mid.values(), newid2mid.keys()))
    mid2num = {}
    for file in os.listdir(os.path.dirname(os.getcwd()) + '/dataset/weibo/weibocontentwithimage/original-microblog/'):
        mid2num[file.split('_')[-2]] = file.split('_')[0]
    newid2num = {}
    for id in X_train_tid:
        newid2num[id] = mid2num[newid2mid[id]]
    for id in X_dev_tid:
        newid2num[id] = mid2num[newid2mid[id]]
    for id in X_test_tid:
        newid2num[id] = mid2num[newid2mid[id]]
    config['newid2imgnum'] = newid2num

    return X_train_tid, X_train, X_train_UserReview, y_train, \
        X_dev_tid, X_dev, X_dev_UserReview, y_dev, \
        X_test_tid, X_test, X_test_UserReview, y_test


def train_and_test(Tea_model, Stu_model, i):
    model_suffix = Tea_model.__name__.lower().strip("text")
    res_dir = 'exp_result'
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)
    res_dir = os.path.join(res_dir, args.task)
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)
    res_dir = os.path.join(res_dir, args.description)
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)
    res_dir = config['save_path'] = os.path.join(res_dir, 'best_model_in_each_config')
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)
    config['save_path'] = os.path.join(res_dir, args.thread_name + '_' + 'config' + args.config_name.split(".")[
        0] + '_best_model_weights_' + model_suffix + '_' + str(i))
    #
    dir_path = os.path.join('exp_result', args.task, args.description)
    if not os.path.exists(dir_path):
        os.mkdir(dir_path)
    if os.path.exists(config['save_path']):
        os.system('rm {}'.format(config['save_path']))

    X_train_tid, X_train, X_train_UserReview, y_train, \
        X_dev_tid, X_dev, X_dev_UserReview, y_dev, \
        X_test_tid, X_test, X_test_UserReview, y_test = load_dataset()

    Tea_model.load_state_dict(torch.load('/home/dell/KD3_Save/01_Weibo_KD_01/Best_model'))
    Stu_model = Stu_model(config)
    Stu_model.fit(Tea_model, X_train_tid, X_train, X_train_UserReview, y_train,
                  X_dev_tid, X_dev, X_dev_UserReview, y_dev)
    y_pred = Stu_model.predict(X_test_tid, X_test, X_test_UserReview)

    torch.save(Stu_model.state_dict(), '/home/dell/KD3_Save/01_Weibo_KD_01/Student_model_02/T_'+ str(i) +'.pt')


    res = classification_report(y_test, y_pred, target_names=config['target_names'], digits=3, output_dict=True)
    for k, v in res.items():
        print(k, v)
    print("result:{:.4f}".format(res['accuracy']))
    res2 = {}
    res_final = {}
    res_final.update(res)
    res_final.update(res2)
    return res


config = process_config(config_file.config)
result = {}
Mid_max = 0


seed = config['seed']
torch.cuda.manual_seed_all(seed)
np.random.seed(seed)
random.seed(seed)

Tea_model = MFAN2
Stu_model = MFAN
res = train_and_test(Tea_model, Stu_model, i + 1)


