import os

os.environ["CUDA_VISIBLE_DEVICES"] = "0"
from sklearn.metrics import classification_report, accuracy_score
import csv
from sklearn.metrics.pairwise import cosine_similarity
import torch
from rkd import RKD
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import abc
import torch.nn.utils as utils
import torchvision.models as models
from torchvision import transforms
from torch.utils.data import DataLoader
from torch.utils.data import TensorDataset
import torch.nn.init as init
import pickle
import json, os
import argparse
import config_file
import random
import sys
from PIL import Image
from loss_func import SupConLoss
import warnings

warnings.filterwarnings('ignore')

sys.path.append('/../image_part')
# lambda_kd = 3.0  # 蒸馏温度

def process_config(config):
    for k, v in config.items():
        config[k] = v[0]
    return config


class PGD(object):
    def __init__(self, model, emb_name, epsilon=1., alpha=0.3):
        self.model = model
        self.emb_name = emb_name
        self.epsilon = epsilon
        self.alpha = alpha
        self.emb_backup = {}
        self.grad_backup = {}

    def attack(self, is_first_attack=False):
        for name, param in self.model.named_parameters():
            if param.requires_grad and self.emb_name in name:
                if is_first_attack:
                    self.emb_backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm != 0:
                    r_at = self.alpha * param.grad / norm
                    param.data.add_(r_at)
                    param.data = self.project(name, param.data, self.epsilon)

    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and self.emb_name in name:
                assert name in self.emb_backup
                param.data = self.emb_backup[name]
        self.emb_backup = {}

    def project(self, param_name, param_data, epsilon):
        r = param_data - self.emb_backup[param_name]
        if torch.norm(r) > epsilon:
            r = epsilon * r / torch.norm(r)
        return self.emb_backup[param_name] + r

    def backup_grad(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and param.grad is not None:
                self.grad_backup[name] = param.grad.clone()

    def restore_grad(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and param.grad is not None:
                param.grad = self.grad_backup[name]


class TransformerBlock(nn.Module):

    def __init__(self, input_size, d_k=16, d_v=16, n_heads=8, is_layer_norm=False, attn_dropout=0.1):
        super(TransformerBlock, self).__init__()
        self.n_heads = n_heads
        self.d_k = d_k if d_k is not None else input_size
        self.d_v = d_v if d_v is not None else input_size

        self.is_layer_norm = is_layer_norm
        if is_layer_norm:
            self.layer_morm = nn.LayerNorm(normalized_shape=input_size)

        self.W_q = nn.Parameter(torch.Tensor(input_size, n_heads * d_k))
        self.W_k = nn.Parameter(torch.Tensor(input_size, n_heads * d_k))
        self.W_v = nn.Parameter(torch.Tensor(input_size, n_heads * d_v))

        self.W_o = nn.Parameter(torch.Tensor(d_v * n_heads, input_size))
        self.linear1 = nn.Linear(input_size, input_size)
        self.linear2 = nn.Linear(input_size, input_size)

        self.dropout = nn.Dropout(attn_dropout)
        self.__init_weights__()

    def __init_weights__(self):
        init.xavier_normal_(self.W_q)
        init.xavier_normal_(self.W_k)
        init.xavier_normal_(self.W_v)
        init.xavier_normal_(self.W_o)

        init.xavier_normal_(self.linear1.weight)
        init.xavier_normal_(self.linear2.weight)

    def FFN(self, X):
        output = self.linear2(F.relu(self.linear1(X)))
        output = self.dropout(output)
        return output

    def scaled_dot_product_attention(self, Q, K, V, episilon=1e-6):
        '''
        :param Q: (*, max_q_words, n_heads, input_size)
        :param K: (*, max_k_words, n_heads, input_size)
        :param V: (*, max_v_words, n_heads, input_size)
        :param episilon:
        :return:
        '''
        temperature = self.d_k ** 0.5
        Q_K = torch.einsum("bqd,bkd->bqk", Q, K) / (temperature + episilon)
        Q_K_score = F.softmax(Q_K, dim=-1)
        Q_K_score = self.dropout(Q_K_score)

        V_att = Q_K_score.bmm(V)
        return V_att

    def multi_head_attention(self, Q, K, V):
        bsz, q_len, _ = Q.size()
        bsz, k_len, _ = K.size()
        bsz, v_len, _ = V.size()

        Q_ = Q.matmul(self.W_q).view(bsz, q_len, self.n_heads, self.d_k)
        K_ = K.matmul(self.W_k).view(bsz, k_len, self.n_heads, self.d_k)
        V_ = V.matmul(self.W_v).view(bsz, v_len, self.n_heads, self.d_v)

        Q_ = Q_.permute(0, 2, 1, 3).contiguous().view(bsz * self.n_heads, q_len, self.d_k)
        K_ = K_.permute(0, 2, 1, 3).contiguous().view(bsz * self.n_heads, q_len, self.d_k)
        V_ = V_.permute(0, 2, 1, 3).contiguous().view(bsz * self.n_heads, q_len, self.d_v)

        V_att = self.scaled_dot_product_attention(Q_, K_, V_)
        V_att = V_att.view(bsz, self.n_heads, q_len, self.d_v)
        V_att = V_att.permute(0, 2, 1, 3).contiguous().view(bsz, q_len, self.n_heads * self.d_v)

        output = self.dropout(V_att.matmul(self.W_o))
        return output

    def forward(self, Q, K, V):
        '''
        :param Q: (batch_size, max_q_words, input_size)
        :param K: (batch_size, max_k_words, input_size)
        :param V: (batch_size, max_v_words, input_size)
        :return:  output: (batch_size, max_q_words, input_size)  same size as Q
        '''
        V_att = self.multi_head_attention(Q, K, V)

        if self.is_layer_norm:
            X = self.layer_morm(Q + V_att)
            output = self.layer_morm(self.FFN(X) + X)
        else:
            X = Q + V_att
            output = self.FFN(X) + X
        return output

# 蒸馏部分：定义kd的loss
def distillation(y, labels, teacher_scores, temp):
    """
    :param y: 学生预测的概率分布
    :param labels: 实际标签
    :param teacher_scores: 老师预测的概率分布
    :param temp: 温度系数
    :param alpha: 损失调整因子
    :return:
    """
    kl_stu_tea = nn.KLDivLoss()(F.log_softmax(y / temp, dim=1),
                                F.softmax(teacher_scores / temp, dim=1)) * temp * temp * 2.0
    # stu_loss = F.cross_entropy(y, labels) * (1 - alpha)

    # return kl_stu_tea + stu_loss
    return kl_stu_tea


class NeuralNetwork(nn.Module):

    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.best_acc = 0
        self.init_clip_max_norm = None
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    @abc.abstractmethod
    def forward(self, x_tid, x_text, x_UserReview):
        pass

    def mfan(self,Tea_model,x_tid, x_text, x_UserReview, y, loss, criterionKD,i, total, params, pgd_word):

        Tea_model.eval()
        logit = Tea_model.predict(x_tid, x_text, x_UserReview)

        self.optimizer.zero_grad()
        logit_original, embedding_train = self.forward(x_tid, x_text, x_UserReview)
        alpha1 = 0.7
        kd_loss = distillation(logit_original, y, logit, temp=5.0)
        loss_classification = loss(logit_original, y)
        loss_defense = loss_classification * (1 - alpha1) + kd_loss * alpha1
        loss_defense.backward()

        K = 3
        pgd_word.backup_grad()
        for t in range(K):
            pgd_word.attack(is_first_attack=(t == 0))
            if t != K - 1:
                self.zero_grad()
            else:
                pgd_word.restore_grad()
            loss_adv, embedding_adv = self.forward(x_tid, x_text, x_UserReview)
            logit1 = Tea_model.predict(x_tid, x_text, x_UserReview)
            kd_loss = distillation(loss_adv, y, logit1, temp=5.0)
            loss_adv = (loss(loss_adv, y) * (1 - alpha1)) + (kd_loss * alpha1)
            loss_adv.backward()

        pgd_word.restore()
        self.optimizer.step()
        corrects = (torch.max(logit_original, 1)[1].view(y.size()).data == y.data).sum()
        accuracy = 100 * corrects / len(y)
        print(
            'Batch[{}/{}] - loss: {:.6f}  accuracy: {:.4f}%({}/{})'.format(i + 1, total,
                                                                           loss_defense.item(),
                                                                           accuracy,
                                                                           corrects,
                                                                           y.size(0)))

    def fit(self, Tea_model,X_train_tid, X_train, X_train_UserReview, y_train,
            X_dev_tid, X_dev, X_dev_UserReview, y_dev):

        if torch.cuda.is_available():
            self.cuda()
        else:
            self.cpu()
        batch_size = self.config['batch_size']
        self.optimizer = torch.optim.Adam(self.parameters(), lr=2e-3, weight_decay=0)

        X_train_tid = torch.LongTensor(X_train_tid)
        X_train = torch.LongTensor(X_train)
        X_train_UserReview = torch.LongTensor(X_train_UserReview)
        y_train = torch.LongTensor(y_train)

        dataset = TensorDataset(X_train_tid, X_train, X_train_UserReview, y_train)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)
        loss = nn.CrossEntropyLoss()
        criterionKD = RKD(25, 50)

        params = [(name, param) for name, param in self.named_parameters()]
        pgd_word = PGD(self, emb_name='word_embedding', epsilon=6, alpha=1.8)

        for epoch in range(self.config['epochs']):
            print("\nEpoch ", epoch + 1, "/", self.config['epochs'],'正在训练.....')
            self.train()
            for i, data in enumerate(dataloader):
                total = len(dataloader)
                batch_x_tid, batch_x_text, batch_x_UserReview, batch_y = (item.cuda(device=self.device) for item in
                                                                          data)
                self.mfan(Tea_model,batch_x_tid, batch_x_text, batch_x_UserReview, batch_y, loss, criterionKD, i, total, params, pgd_word)

                if self.init_clip_max_norm is not None:
                    utils.clip_grad_norm_(self.parameters(), max_norm=self.init_clip_max_norm)
            self.evaluate(X_dev_tid, X_dev, X_dev_UserReview, y_dev)

    def evaluate(self, X_dev_tid, X_dev, X_dev_UserReview, y_dev):
        y_pred = self.predict(X_dev_tid, X_dev, X_dev_UserReview)
        acc = accuracy_score(y_dev, y_pred)

        if acc > self.best_acc:
            self.best_acc = acc
            torch.save(self.state_dict(), self.config['save_path'])
            print(classification_report(y_dev, y_pred, target_names=self.config['target_names'], digits=5))
            print("Val set acc:", acc)
            print("Best val set acc:", self.best_acc)
            print("saved model at ", self.config['save_path'])

    def predict(self, X_test_tid, X_test, X_test_UserReview):
        if torch.cuda.is_available():
            self.cuda()
        self.eval()
        y_pred = []
        X_test_tid = torch.LongTensor(X_test_tid).cuda()
        X_test = torch.LongTensor(X_test).cuda()
        X_test_UserReview = torch.LongTensor(X_test_UserReview).cuda()

        dataset = TensorDataset(X_test_tid, X_test, X_test_UserReview)
        dataloader = DataLoader(dataset, batch_size=50)

        for i, data in enumerate(dataloader):
            with torch.no_grad():
                batch_x_tid, batch_x_text, batch_x_UserReview = (item.cuda(device=self.device) for item in data)
                # logits, dist, embedding = self.forward(batch_x_tid, batch_x_text, batch_x_UserReview)
                logits, embedding = self.forward(batch_x_tid, batch_x_text, batch_x_UserReview)
                predicted = torch.max(logits, dim=1)[1]
                y_pred += predicted.data.cpu().numpy().tolist()
        return y_pred

class NeuralNetwork2(nn.Module):

    def __init__(self):
        super(NeuralNetwork2, self).__init__()
        self.best_acc = 0
        self.init_clip_max_norm = None
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    @abc.abstractmethod
    def forward(self, x_tid, x_text, x_UserReview):
        pass

    def predict(self, X_test_tid, X_test, X_test_UserReview):
        if torch.cuda.is_available():
            self.cuda()
        self.eval()
        # y_pred = []
        with torch.no_grad():
            # logits, dist, embedding = self.forward(X_test_tid, X_test, X_test_UserReview)
            logits, embedding = self.forward(X_test_tid, X_test, X_test_UserReview)
            # predicted = torch.max(logits, dim=1)[1]
            # y_pred += predicted.data.cpu().numpy().tolist()
        return logits


class resnet50():
    def __init__(self):
        self.newid2imgnum = config['newid2imgnum']
        self.model = models.resnet50(pretrained=True).cuda()
        self.model.fc = nn.Linear(2048, 300).cuda()
        torch.nn.init.eye_(self.model.fc.weight)
        self.path = os.path.dirname(os.getcwd()) + '/dataset/pheme/pheme_image/pheme_images_jpg/'
        self.trans = self.img_trans()

    def img_trans(self):
        transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )])
        return transform

    def forward(self, xtid):
        img_list = []
        for newid in xtid.cpu().numpy():
            imgnum = self.newid2imgnum[newid]
            imgpath = self.path + imgnum + '.jpg'
            im = np.array(self.trans(Image.open(imgpath)))
            im = torch.from_numpy(np.expand_dims(im, axis=0)).to(torch.float32)
            img_list.append(im)
        batch_img = torch.cat(img_list, dim=0).cuda()
        img_output = self.model(batch_img)
        return img_output


class MFAN(NeuralNetwork):
    def __init__(self, config):
        super(MFAN, self).__init__()
        self.config = config
        embedding_weights = config['embedding_weights']
        V, D = embedding_weights.shape
        maxlen = config['maxlen']
        dropout_rate = config['dropout']

        self.mh_attention = TransformerBlock(input_size=300, n_heads=8, attn_dropout=0)
        self.word_embedding = nn.Embedding(num_embeddings=V, embedding_dim=D, padding_idx=0,
                                           _weight=torch.from_numpy(embedding_weights))
        self.image_embedding = resnet50()
        self.convs = nn.ModuleList([nn.Conv1d(300, 100, kernel_size=K) for K in config['kernel_sizes']])
        self.max_poolings = nn.ModuleList([nn.MaxPool1d(kernel_size=maxlen - K + 1) for K in config['kernel_sizes']])
        self.dropout = nn.Dropout(dropout_rate)
        self.relu = nn.ReLU()
        self.fc3 = nn.Linear(1800, 900)
        self.fc4 = nn.Linear(900, 600)
        self.fc1 = nn.Linear(300, 300)
        self.fc0 = nn.Linear(300, 300)
        self.fc2 = nn.Linear(in_features=300, out_features=config['num_classes'])
        self.alignfc_g = nn.Linear(in_features=300, out_features=300)
        self.alignfc_t = nn.Linear(in_features=300, out_features=300)
        self.init_weight()

    def init_weight(self):
        init.xavier_normal_(self.fc0.weight)
        init.xavier_normal_(self.fc1.weight)
        init.xavier_normal_(self.fc2.weight)
        init.xavier_normal_(self.fc3.weight)
        init.xavier_normal_(self.fc4.weight)

    def forward(self, X_tid, X_text, X_UserReview):
        X_text = self.word_embedding(X_text)
        # X_UserReview = self.word_embedding(X_UserReview)

        if self.config['user_self_attention'] == True:
            X_text = self.mh_attention(X_text, X_text, X_text)

        X_text = X_text.permute(0, 2, 1)

        # 文本
        conv_block = []
        for _, (Conv, max_pooling) in enumerate(zip(self.convs, self.max_poolings)):
            act = self.relu(Conv(X_text))
            pool = max_pooling(act)
            pool = torch.squeeze(pool)
            conv_block.append(pool)
        conv_feature = torch.cat(conv_block, dim=1)
        text_feature = conv_feature

        a1 = self.relu(self.dropout(self.fc1(text_feature)))
        a1 = self.relu(self.fc0(a1))
        d1 = self.dropout(a1)
        output = self.fc2(d1)

        return output, d1

class MFAN2(NeuralNetwork2):
    def __init__(self, config):
        super(MFAN2, self).__init__()
        self.config = config
        embedding_weights = config['embedding_weights']
        V, D = embedding_weights.shape
        maxlen = config['maxlen']
        dropout_rate = config['dropout']

        self.mh_attention = TransformerBlock(input_size=300, n_heads=8, attn_dropout=0)
        self.word_embedding = nn.Embedding(num_embeddings=V, embedding_dim=D, padding_idx=0,
                                           _weight=torch.from_numpy(embedding_weights))
        self.image_embedding = resnet50()
        self.convs = nn.ModuleList([nn.Conv1d(300, 100, kernel_size=K) for K in config['kernel_sizes']])
        self.max_poolings = nn.ModuleList([nn.MaxPool1d(kernel_size=maxlen - K + 1) for K in config['kernel_sizes']])
        self.dropout = nn.Dropout(dropout_rate)
        self.relu = nn.ReLU()
        self.fc3 = nn.Linear(1800, 900)
        self.fc4 = nn.Linear(900, 600)
        self.fc1 = nn.Linear(600, 300)
        self.fc2 = nn.Linear(in_features=300, out_features=config['num_classes'])
        self.alignfc_g = nn.Linear(in_features=300, out_features=300)
        self.alignfc_t = nn.Linear(in_features=300, out_features=300)
        self.init_weight()

    def init_weight(self):
        init.xavier_normal_(self.fc1.weight)
        init.xavier_normal_(self.fc2.weight)
        init.xavier_normal_(self.fc3.weight)
        init.xavier_normal_(self.fc4.weight)

    def forward(self, X_tid, X_text, X_UserReview):
        X_text = self.word_embedding(X_text)
        X_UserReview = self.word_embedding(X_UserReview)

        if self.config['user_self_attention'] == True:
            X_text = self.mh_attention(X_text, X_text, X_text)

        X_text = X_text.permute(0, 2, 1)

        X_UserReview = X_UserReview.permute(0, 2, 1)
        # 图像
        iembedding = self.image_embedding.forward(X_tid)

        # 用户评论
        conv_block1 = []
        for _, (Conv, max_pooling) in enumerate(zip(self.convs, self.max_poolings)):
            act1 = self.relu(Conv(X_UserReview))
            pool1 = max_pooling(act1)
            pool1 = torch.squeeze(pool1)
            conv_block1.append(pool1)
        conv_feature = torch.cat(conv_block1, dim=1)
        UserReview_feature = conv_feature

        # 文本
        conv_block = []
        for _, (Conv, max_pooling) in enumerate(zip(self.convs, self.max_poolings)):
            act = self.relu(Conv(X_text))
            pool = max_pooling(act)
            pool = torch.squeeze(pool)
            conv_block.append(pool)
        conv_feature = torch.cat(conv_block, dim=1)
        text_feature = conv_feature
        bsz = text_feature.size()[0]

        self_att_t = self.mh_attention(text_feature.view(bsz, -1, 300), text_feature.view(bsz, -1, 300), \
                                       text_feature.view(bsz, -1, 300))
        self_att_i = self.mh_attention(iembedding.view(bsz, -1, 300), iembedding.view(bsz, -1, 300), \
                                       iembedding.view(bsz, -1, 300))

        text_enhanced = self.mh_attention(self_att_i.view((bsz, -1, 300)), self_att_t.view((bsz, -1, 300)), \
                                          self_att_t.view((bsz, -1, 300))).view(bsz, 300)
        align_text = self.alignfc_t(text_enhanced)
        # dist = [align_text]
        self_att_t = text_enhanced.view((bsz, -1, 300))
        co_att_ti = self.mh_attention(self_att_t, self_att_i, self_att_i).view(bsz, 300)
        co_att_it = self.mh_attention(self_att_i, self_att_t, self_att_t).view(bsz, 300)

        att_feature = torch.cat((co_att_ti, co_att_it, UserReview_feature), dim=1)

        a1 = self.relu(self.dropout(self.fc4(att_feature)))
        a1 = self.relu(self.fc1(a1))
        d1 = self.dropout(a1)
        output = self.fc2(d1)

        # return output, dist, d1
        return output, d1



def load_dataset():
    pre = os.path.dirname(os.getcwd()) + '/dataset/pheme/pheme_files/'
    X_train_tid, X_train, X_train_UserReview, y_train, word_embeddings, _ = pickle.load(
        open(pre + "/train.pkl", 'rb'))
    X_dev_tid, X_dev, X_dev_UserReview, y_dev = pickle.load(open(pre + "/dev.pkl", 'rb'))
    X_test_tid, X_test, X_test_UserReview, y_test = pickle.load(open(pre + "/test.pkl", 'rb'))
    config['embedding_weights'] = word_embeddings
    config['node_embedding'] = pickle.load(open(pre + "/node_embedding.pkl", 'rb'))[0]

    with open(pre + '/new_id_dic.json', 'r') as f:
        newid2mid = json.load(f)
        newid2mid = dict(zip(newid2mid.values(), newid2mid.keys()))
    content_path = os.path.dirname(os.getcwd()) + '/dataset/pheme/'
    with open(content_path + '/content.csv', 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        result = list(reader)[1:]
        mid2num = {}
        for line in result:
            mid2num[line[1]] = line[0]
    newid2num = {}
    for id in X_train_tid:
        newid2num[id] = mid2num[newid2mid[id]]
    for id in X_dev_tid:
        newid2num[id] = mid2num[newid2mid[id]]
    for id in X_test_tid:
        newid2num[id] = mid2num[newid2mid[id]]
    config['newid2imgnum'] = newid2num

    return X_train_tid, X_train, X_train_UserReview, y_train, \
        X_dev_tid, X_dev, X_dev_UserReview, y_dev, \
        X_test_tid, X_test, X_test_UserReview, y_test


def train_and_test(Tea_model, Stu_model):
    model_suffix = Stu_model.__name__.lower().strip("text")
    res_dir = 'exp_result'
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)
    res_dir = os.path.join(res_dir, args.task)
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)
    res_dir = os.path.join(res_dir, args.description)
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)
    res_dir = config['save_path'] = os.path.join(res_dir, 'best_model_in_each_config')
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)
    config['save_path'] = os.path.join(res_dir, args.thread_name + '_' + 'config' + args.config_name.split(".")[
        0] + '_best_model_weights_' + model_suffix + '_' + str(i))
    dir_path = os.path.join('exp_result', args.task, args.description)
    if not os.path.exists(dir_path):
        os.mkdir(dir_path)
    if os.path.exists(config['save_path']):
        os.system('rm {}'.format(config['save_path']))

    X_train_tid, X_train, X_train_UserReview, y_train, \
        X_dev_tid, X_dev, X_dev_UserReview, y_dev, \
        X_test_tid, X_test, X_test_UserReview, y_test = load_dataset()

    # 加载模型
    Tea_model.load_state_dict(torch.load('/home/dell/KD3/02_Pheme_KD_01/Tea_model'))

    # 学生模型
    Stu_model = Stu_model(config)
    Stu_model.fit(Tea_model, X_train_tid, X_train, X_train_UserReview, y_train,
                  X_dev_tid, X_dev, X_dev_UserReview, y_dev)
    y_pred = Stu_model.predict(X_test_tid, X_test, X_test_UserReview)


    res = classification_report(y_test, y_pred, target_names=config['target_names'], digits=3, output_dict=True)
    print("测试结果：")
    for k, v in res.items():
        print(k, v)
    print("result:{:.4f}".format(res['accuracy']))
    res2 = {}
    res_final = {}
    res_final.update(res)
    res_final.update(res2)
    # print(res)
    return res


alpha1 = 0.5
temp1 = 0.5
parser = argparse.ArgumentParser()
parser.description = "ini"
parser.add_argument("-t", "--task", type=str, default="pheme")
parser.add_argument("-g", "--gpu_id", type=str, default="1")
parser.add_argument("-c", "--config_name", type=str, default="single3.json")
parser.add_argument("-T", "--thread_name", type=str, default="Thread-1")
parser.add_argument("-d", "--description", type=str, default="exp_description")
args = parser.parse_args()

config = process_config(config_file.config)
result = {}

seed = config['seed']
torch.cuda.manual_seed_all(seed)
np.random.seed(seed)
random.seed(seed)

Tea_model = MFAN2
Stu_model = MFAN
res = train_and_test(Tea_model, Stu_model)

